"""This script is used to filter the results we got from ChatGPT when we analyse portuguese documents 
"""

# this is the name of the file generated by the openai_script_en.py script
filename = "chatgpt.txt"
# stopwords to divide the results we got
stopwords = [
    "Person names",
    "Company names",
    "Companies",
    "Specific topics",
    "General topics",
]
results = {}


def get_results(filename):
    """Transform the file with the results into a list of results

    Args:
        filename (string): file path of the file with the results

    Returns:
        string []: returns a list with all the results
    """
    word_list = []
    with open(filename, "r", encoding="utf-8") as f:
        for line in f:
            word_list.append(line.split("\n"))

    for l in range(len(word_list)):
        word_list[l] = [x for x in word_list[l] if x != "---" and x != ""]

    word_list = [l for l in word_list if l != []]
    # print(word_list)
    return word_list


def get_summary(word_list):
    """From the file with the results we are extracting all the summaries we got from ChatGPT

    Args:
        word_list (string []): list with all the results

    Returns:
        word_list (string []): returns the list with all the resutls except the summaries
        summary (string []): returns the list with all the summaries
    """
    summary = []
    for l in word_list:
        for word in l:
            for x in stopwords:
                if "abstract" not in word.lower():
                    if x in word:
                        new_word = word.split(":")[1]
                        l.append(new_word)
                        l.remove(word)

    l = 0
    while l < len(word_list):
        w = 0
        while w < len(word_list[l]):
            if "abstract" in word_list[l][w].lower():
                new_word = word_list[l][w].split(":")[1]
                summary.append(new_word)
                word_list.remove(word_list[l])
                l -= 1
                break
            w += 1
        l += 1
    # print(summary)

    summary = list(map(lambda s: s.strip(), summary))

    """ 
    write a file with all the summaries of every response we got
    """
    with open("summary.txt", "w", encoding="utf-8") as f:
        f.flush()
        for s in summary:
            f.write("%s " % s)
        f.close()

    return word_list, summary


def categorize_words(word_list):
    """From the original file with all the results we are extracting all the results and separate them by categories
    For each category we remove the duplicate results and the null results
    In the end we get 4 files, each corresponding to each category

    Args:
        word_list (string []): list with all the results
    """
    people = []
    companies = []
    specifics = []
    general = []

    for l in range(int(len(word_list) / 4)):
        for w in range(len(word_list[l])):
            people.extend(word_list[l * 4][w].split(","))
            companies.extend(word_list[l * 4 + 1][w].split(","))
            specifics.extend(word_list[l * 4 + 2][w].split(","))
            general.extend(word_list[l * 4 + 3][w].split(","))

    people = list(map(lambda p: p.strip(), people))
    people = [p.lower() for p in people]

    people = [
        p
        for p in people
        if p != "-"
        and p != ""
        and p != "-||-"
        and "n/a" not in p
        and "none" not in p
        and "none mentioned" not in p
    ]
    people = list(dict.fromkeys(people))

    with open("people.txt", "w", encoding="utf-8") as f:
        f.flush()
        for p in people:
            f.write("%s\n" % p)
        f.close()

    companies = list(map(lambda c: c.strip(), companies))
    companies = [c.lower() for c in companies]

    companies = [
        c
        for c in companies
        if c != "-"
        and c != "-||-"
        and "n/a" not in c
        and "none" not in c
        and "none mentioned" not in c
    ]
    companies = list(dict.fromkeys(companies))

    with open("companies.txt", "w", encoding="utf-8") as f:
        f.flush()
        for c in companies:
            f.write("%s\n" % c)
        f.close()

    specifics = list(map(lambda s: s.strip(), specifics))
    specifics = [s.lower() for s in specifics]

    for s in range(len(specifics)):
        if specifics[s][-1] == ".":
            specifics[s] = specifics[s][:-1]

    specifics = list(dict.fromkeys(specifics))

    with open("specifics.txt", "w", encoding="utf-8") as f:
        f.flush()
        for s in specifics:
            f.write("%s\n" % s)
        f.close()

    general = list(map(lambda g: g.strip(), general))
    general = [g.lower() for g in general]

    for g in range(len(general)):
        if general[g][-1] == ".":
            general[g] = general[g][:-1]

    general = list(dict.fromkeys(general))

    with open("general.txt", "w", encoding="utf-8") as f:
        f.flush()
        for g in general:
            f.write("%s\n" % g)
        f.close()

    results["people"] = people
    results["companies"] = companies
    results["specifics"] = specifics
    results["general"] = general


l = get_results(filename)
word_list, summary = get_summary(l)
categorize_words(word_list)
